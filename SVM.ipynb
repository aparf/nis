{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machines for Particles Showers Classification##"
      ],
      "metadata": {
        "id": "7rpZ2AbOYCA7"
      },
      "id": "7rpZ2AbOYCA7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machines are among probably the most widely used classical machine learning algorithm used in computer vision. It is widely used as a baseline solutions in comparison with neural networks. As neural networks proved to be hard to train on the given dataset, we tried to apply support vector machines, which are significantly less data hungry and often tend to produce better generalization on small datasets."
      ],
      "metadata": {
        "id": "W2Zc2K_AYPUs"
      },
      "id": "W2Zc2K_AYPUs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading and preprocessing"
      ],
      "metadata": {
        "id": "0sBw-d0dYyXC"
      },
      "id": "0sBw-d0dYyXC"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "36bbb8d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36bbb8d6",
        "outputId": "99ddefab-1ae6-4e81-9f3a-809a1ec3d08b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install h5py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import time, math, copy\n",
        "from tqdm import tqdm\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZC63Lf4dhjv",
        "outputId": "5ba5016d-b4f6-4c95-d40b-fb1fa5c0a64a"
      },
      "id": "uZC63Lf4dhjv",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dd1cc6c0",
      "metadata": {
        "id": "dd1cc6c0"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c49d1bdc",
      "metadata": {
        "id": "c49d1bdc"
      },
      "outputs": [],
      "source": [
        "f = h5py.File(\"/content/gdrive/MyDrive/gamma.hdf5\", 'r') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ca48baa5",
      "metadata": {
        "id": "ca48baa5"
      },
      "outputs": [],
      "source": [
        "with h5py.File(\"/content/gdrive/MyDrive/gamma.hdf5\", 'r') as f:\n",
        "   energy = f['energy'][:]\n",
        "   layer_0 = f['layer_0'][:]\n",
        "   layer_1 = f['layer_1'][:]\n",
        "   layer_2 = f['layer_2'][:]\n",
        "   overflow = f['overflow'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "79729d3e",
      "metadata": {
        "id": "79729d3e"
      },
      "outputs": [],
      "source": [
        "f = h5py.File(\"/content/gdrive/MyDrive/eplus.hdf5\", 'r') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fc509207",
      "metadata": {
        "id": "fc509207"
      },
      "outputs": [],
      "source": [
        "with h5py.File(\"/content/gdrive/MyDrive/eplus.hdf5\", 'r') as f:\n",
        "   energy_ep = f['energy'][:]\n",
        "   layer_0_ep = f['layer_0'][:]\n",
        "   layer_1_ep = f['layer_1'][:]\n",
        "   layer_2_ep = f['layer_2'][:]\n",
        "   overflow_ep = f['overflow'][:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_0_flat = layer_0.reshape([100000,96*3])\n",
        "layer_1_flat = layer_1.reshape([100000,12*12])\n",
        "layer_2_flat = layer_2.reshape([100000,12*6])\n",
        "\n",
        "layer_0_ep_flat = layer_0_ep.reshape([100000,96*3])\n",
        "layer_1_ep_flat = layer_1_ep.reshape([100000,12*12])\n",
        "layer_2_ep_flat = layer_2_ep.reshape([100000,12*6])\n",
        "\n",
        "gam_data = np.hstack((layer_0_flat,layer_1_flat,layer_2_flat))\n",
        "ep_data = np.hstack((layer_0_ep_flat,layer_1_ep_flat,layer_2_ep_flat))\n",
        "labels = np.hstack((np.ones(100000), np.zeros(100000)))"
      ],
      "metadata": {
        "id": "vflC0A2qUGpC"
      },
      "id": "vflC0A2qUGpC",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tota = np.vstack((gam_data,ep_data))"
      ],
      "metadata": {
        "id": "KwG488UUV0DI"
      },
      "id": "KwG488UUV0DI",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    tota, labels, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "VS0-_BoeWHuQ"
      },
      "id": "VS0-_BoeWHuQ",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indeces = np.arange(134000)\n",
        "indeces_c = np.random.choice(indeces, 10000)"
      ],
      "metadata": {
        "id": "C8F5Zy-UaFhL"
      },
      "id": "C8F5Zy-UaFhL",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TypYJjnaDTp",
        "outputId": "b493d444-3c47-407f-961d-5de50ba2e0d0"
      },
      "id": "9TypYJjnaDTp",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134000"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC(probability = True, kernel = 'linear')\n",
        "\n",
        "clf.fit(X_train[indeces_c], y_train[indeces_c])\n",
        "\n",
        "print(clf.score(X_test,y_test))"
      ],
      "metadata": {
        "id": "HYgnMerXWSnh"
      },
      "id": "HYgnMerXWSnh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}