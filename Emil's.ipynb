{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36bbb8d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36bbb8d6",
        "outputId": "84663d1b-1404-4705-f6b5-755c4337cb1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3a244a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3a244a8",
        "outputId": "de314956-eb75-45a1-c67a-f505a18a50a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import time, math, copy\n",
        "from tqdm import tqdm\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZC63Lf4dhjv",
        "outputId": "b2dc0944-5aba-4e29-cdb0-32fe770eb7c8"
      },
      "id": "uZC63Lf4dhjv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd1cc6c0",
      "metadata": {
        "id": "dd1cc6c0"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c49d1bdc",
      "metadata": {
        "id": "c49d1bdc"
      },
      "outputs": [],
      "source": [
        "f = h5py.File(\"/content/gdrive/MyDrive/gamma.hdf5\", 'r') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.hist(energy, bins='auto')"
      ],
      "metadata": {
        "id": "nEAkp8nLqbyI"
      },
      "id": "nEAkp8nLqbyI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca48baa5",
      "metadata": {
        "id": "ca48baa5"
      },
      "outputs": [],
      "source": [
        "with h5py.File(\"/content/gdrive/MyDrive/gamma.hdf5\", 'r') as f:\n",
        "   energy = f['energy'][:]\n",
        "   layer_0 = f['layer_0'][:]\n",
        "   layer_1 = f['layer_1'][:]\n",
        "   layer_2 = f['layer_2'][:]\n",
        "   overflow = f['overflow'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79729d3e",
      "metadata": {
        "id": "79729d3e"
      },
      "outputs": [],
      "source": [
        "f = h5py.File(\"/content/gdrive/MyDrive/eplus.hdf5\", 'r') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc509207",
      "metadata": {
        "id": "fc509207"
      },
      "outputs": [],
      "source": [
        "with h5py.File(\"/content/gdrive/MyDrive/eplus.hdf5\", 'r') as f:\n",
        "   energy_ep = f['energy'][:]\n",
        "   layer_0_ep = f['layer_0'][:]\n",
        "   layer_1_ep = f['layer_1'][:]\n",
        "   layer_2_ep = f['layer_2'][:]\n",
        "   overflow_ep = f['overflow'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd5c0a6a",
      "metadata": {
        "id": "dd5c0a6a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, Subset\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, labels, layer_0, layer_1,layer_02):\n",
        "        self.labels = labels\n",
        "        self.layer_0 = layer_0 \n",
        "        self.layer_1 = layer_1\n",
        "        self.layer_2 = layer_2\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image1 = layer_0[idx]\n",
        "        image2 = layer_1[idx]\n",
        "        image3 = layer_2[idx]\n",
        "        label = self.labels[idx]\n",
        "        return (image1,image2,image3), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3486423",
      "metadata": {
        "id": "d3486423"
      },
      "outputs": [],
      "source": [
        "dataset_gamma = CustomImageDataset(np.ones(100000),layer_0,layer_1,layer_2)\n",
        "dataset_ep = CustomImageDataset(np.zeros(100000),layer_0_ep,layer_1_ep,layer_2_ep)\n",
        "total_data = torch.utils.data.ConcatDataset([dataset_gamma, dataset_ep])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7862fc72",
      "metadata": {
        "id": "7862fc72"
      },
      "outputs": [],
      "source": [
        "N = len(total_data)\n",
        "\n",
        "# generate & shuffle indices\n",
        "indices = np.arange(N)\n",
        "indices = np.random.permutation(indices)\n",
        "# there are many ways to do the above two operation. (Example, using np.random.choice can be used here too\n",
        "\n",
        "# select train/test/val, for demo I am using 70,15,15\n",
        "train_indices = indices [:int(0.7*N)]\n",
        "val_indices = indices[int(0.7*N):int(0.85*N)]\n",
        "test_indices = indices[int(0.85*N):]\n",
        "\n",
        "train_dataset = Subset(total_data, train_indices)\n",
        "val_dataset = Subset(total_data, val_indices)\n",
        "test_dataset = Subset(total_data, test_indices)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-lxMNMqhL_D0"
      },
      "id": "-lxMNMqhL_D0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae5b980a",
      "metadata": {
        "id": "ae5b980a"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "from torch import nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "139d8fba",
      "metadata": {
        "id": "139d8fba"
      },
      "outputs": [],
      "source": [
        "def conv_block(input_size, output_size, kernel_size):\n",
        "    block = nn.Sequential(\n",
        "        nn.Conv2d(input_size, output_size, kernel_size), nn.ReLU(), nn.BatchNorm2d(output_size), nn.MaxPool2d((1, 2)),\n",
        "    )\n",
        "\n",
        "    return block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f032bfb0",
      "metadata": {
        "id": "f032bfb0"
      },
      "outputs": [],
      "source": [
        "class network(nn.Module):\n",
        "    \n",
        "    def __init__(self,):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.input1 = conv_block(1,3,(1,3))\n",
        "        self.input12 =  conv_block(3, 3, (3, 3))\n",
        "        self.input2 = conv_block(1,3,(3, 3))\n",
        "        self.input22 = conv_block(3,3,(3, 3))\n",
        "        self.input3 = nn.Linear(12*6,10)\n",
        "        \n",
        "        \n",
        "        self.bn1 = nn.BatchNorm1d(66)\n",
        "        self.bn2 = nn.BatchNorm1d(24)\n",
        "        self.bn3 = nn.BatchNorm1d(10)\n",
        "        \n",
        "        self.lin1 = nn.Linear(100,40)\n",
        "        self.lin15 = nn.Linear(40,20)\n",
        "        self.lin2 = nn.Linear(20,1)\n",
        "        \n",
        "        self.drop1 = nn.Dropout(p=0.2)\n",
        "        self.drop2 = nn.Dropout(p=0.2)\n",
        "        self.drop3 = nn.Dropout(p=0.2)\n",
        "\n",
        "        self.activ = nn.ReLU()\n",
        "        \n",
        "    def forward(self,x,y,z):\n",
        "        x = self.input1(x.reshape([16,1, 3, 96]).float())\n",
        "        #print(x.shape)\n",
        "        x = self.input12(x).flatten(start_dim=1)\n",
        "\n",
        "        y = self.input2(y.reshape([16, 1, 12, 12]).float())\n",
        "        y = self.input22(y)\n",
        "\n",
        "        y = y.flatten(start_dim=1)\n",
        "  \n",
        "        z = self.activ(self.input3(z.flatten(start_dim=1)))\n",
        "        \n",
        "        h = torch.cat((self.drop1(self.bn1(x)), self.drop2(self.bn2(y)), self.drop3(self.bn3(z))),axis=1)\n",
        "        \n",
        "        h = self.activ(self.lin1(h))\n",
        "        h =  self.activ(self.lin15(h))\n",
        "        h = self.lin2(h)\n",
        "        \n",
        "        return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10414e9",
      "metadata": {
        "id": "b10414e9"
      },
      "outputs": [],
      "source": [
        "heh = network().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1be2ee2e",
      "metadata": {
        "id": "1be2ee2e"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd8351c4",
      "metadata": {
        "id": "bd8351c4"
      },
      "outputs": [],
      "source": [
        "dataloaders = {'train':DataLoader(train_dataset, batch_size=16),'val':DataLoader(val_dataset, batch_size=16), 'test':DataLoader(test_dataset, batch_size=16)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb16efba",
      "metadata": {
        "id": "fb16efba"
      },
      "outputs": [],
      "source": [
        "loss_fn = loss = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a493f112",
      "metadata": {
        "id": "a493f112"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(heh.parameters(), lr=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a25a946",
      "metadata": {
        "id": "9a25a946"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, (data,labels) in enumerate(dataloaders['train']):\n",
        "        # Every data instance is an input + label pair\n",
        "        data0,data1,data2 = data\n",
        "        data0,data1,data2 = data0.to(device),data1.to(device),data2.to(device)\n",
        "       # print(torch.bincount(labels.type(torch.int)))\n",
        "        labels = labels.to(device)\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = heh(data0.float(),data1.float(),data2.float())\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs.float().squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(dataloaders['train']) + i + 1\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05a3136a",
      "metadata": {
        "id": "05a3136a"
      },
      "outputs": [],
      "source": [
        "train_loss = []\n",
        "val_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e6457c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e6457c7",
        "outputId": "8fa3fc78-6987-45fb-c261-b04fc11f7d4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "  batch 1000 loss: 0.6953238577246666\n",
            "  batch 2000 loss: 0.6946346848011017\n",
            "  batch 3000 loss: 0.6949235211014748\n",
            "  batch 4000 loss: 0.6950234887599945\n",
            "  batch 5000 loss: 0.695378478884697\n",
            "  batch 6000 loss: 0.6946329537034035\n",
            "  batch 7000 loss: 0.694698725938797\n",
            "  batch 8000 loss: 0.6948249584436417\n",
            "LOSS train 0.6948249584436417 valid 0.6931475988490663\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 0.6948966245651245\n",
            "  batch 2000 loss: 0.6945847621560097\n",
            "  batch 3000 loss: 0.6948951486349105\n",
            "  batch 4000 loss: 0.6949359941482544\n",
            "  batch 5000 loss: 0.6953784912824631\n",
            "  batch 6000 loss: 0.6946191759109497\n",
            "  batch 7000 loss: 0.6947209784984588\n",
            "  batch 8000 loss: 0.6948261606097221\n",
            "LOSS train 0.6948261606097221 valid 0.6931565049224223\n",
            "EPOCH 3:\n",
            "  batch 1000 loss: 0.6948967332839966\n",
            "  batch 2000 loss: 0.6945813648104667\n",
            "  batch 3000 loss: 0.6948873528838158\n",
            "  batch 4000 loss: 0.6949934104084968\n",
            "  batch 5000 loss: 0.6953602090477944\n",
            "  batch 6000 loss: 0.6945862766504288\n",
            "  batch 7000 loss: 0.6947143570184707\n",
            "  batch 8000 loss: 0.6948287004828453\n",
            "LOSS train 0.6948287004828453 valid 0.6931626004104968\n",
            "EPOCH 4:\n",
            "  batch 1000 loss: 0.6948935967683793\n",
            "  batch 2000 loss: 0.6945842573046684\n",
            "  batch 3000 loss: 0.6948909862041474\n",
            "  batch 4000 loss: 0.6949976463317871\n",
            "  batch 5000 loss: 0.6953579733967781\n",
            "  batch 6000 loss: 0.6946130528450012\n",
            "  batch 7000 loss: 0.6947011194825172\n",
            "  batch 8000 loss: 0.6948271749615669\n",
            "LOSS train 0.6948271749615669 valid 0.6931670232822033\n",
            "EPOCH 5:\n",
            "  batch 1000 loss: 0.6948759568333626\n",
            "  batch 2000 loss: 0.6945780524015427\n",
            "  batch 3000 loss: 0.6948960111737251\n",
            "  batch 4000 loss: 0.6949942400455474\n",
            "  batch 5000 loss: 0.6953523740172386\n",
            "  batch 6000 loss: 0.6946034318208695\n",
            "  batch 7000 loss: 0.6947105882167817\n",
            "  batch 8000 loss: 0.6948278671503068\n",
            "LOSS train 0.6948278671503068 valid 0.6931637916069633\n",
            "EPOCH 6:\n",
            "  batch 1000 loss: 0.6948964438438415\n",
            "  batch 2000 loss: 0.694580262362957\n",
            "  batch 3000 loss: 0.6948883544802665\n",
            "  batch 4000 loss: 0.694994932949543\n",
            "  batch 5000 loss: 0.6953573336005211\n",
            "  batch 6000 loss: 0.6946001075506211\n",
            "  batch 7000 loss: 0.6946893745660782\n",
            "  batch 8000 loss: 0.6948174953460693\n",
            "LOSS train 0.6948174953460693 valid 0.6931533642854386\n",
            "EPOCH 7:\n",
            "  batch 1000 loss: 0.6948950229883194\n",
            "  batch 2000 loss: 0.6945602549910546\n",
            "  batch 3000 loss: 0.6949409788250923\n",
            "  batch 4000 loss: 0.6949991660118103\n",
            "  batch 5000 loss: 0.6953694786429405\n",
            "  batch 6000 loss: 0.6946220497488975\n",
            "  batch 7000 loss: 0.6947123759388923\n",
            "  batch 8000 loss: 0.6948345820307732\n",
            "LOSS train 0.6948345820307732 valid 0.6931523203049554\n",
            "EPOCH 8:\n",
            "  batch 1000 loss: 0.6948992893099785\n",
            "  batch 2000 loss: 0.694585057258606\n",
            "  batch 3000 loss: 0.694890742778778\n",
            "  batch 4000 loss: 0.694977852165699\n",
            "  batch 5000 loss: 0.6953552957177163\n",
            "  batch 6000 loss: 0.6946222701072693\n",
            "  batch 7000 loss: 0.6946987746357918\n",
            "  batch 8000 loss: 0.6948112474679947\n",
            "LOSS train 0.6948112474679947 valid 0.6931506087887683\n",
            "EPOCH 9:\n",
            "  batch 1000 loss: 0.6948959559202195\n",
            "  batch 2000 loss: 0.6945740352869034\n",
            "  batch 3000 loss: 0.6948880521655083\n",
            "  batch 4000 loss: 0.6949912761449814\n",
            "  batch 5000 loss: 0.6953588602542877\n",
            "  batch 6000 loss: 0.6946060217618942\n",
            "  batch 7000 loss: 0.6946998824477195\n",
            "  batch 8000 loss: 0.6948031609654427\n",
            "LOSS train 0.6948031609654427 valid 0.6931640446412921\n",
            "EPOCH 10:\n",
            "  batch 1000 loss: 0.694893540084362\n",
            "  batch 2000 loss: 0.6945641919374466\n",
            "  batch 3000 loss: 0.6949046523571014\n",
            "  batch 4000 loss: 0.6949947954416275\n",
            "  batch 5000 loss: 0.6953617377281189\n",
            "  batch 6000 loss: 0.694601921916008\n",
            "  batch 7000 loss: 0.6947054866552352\n",
            "  batch 8000 loss: 0.6948125435113907\n",
            "LOSS train 0.6948125435113907 valid 0.6931526752861837\n",
            "EPOCH 11:\n",
            "  batch 1000 loss: 0.6948847447633744\n",
            "  batch 2000 loss: 0.6945708709955215\n",
            "  batch 3000 loss: 0.6948854714632035\n",
            "  batch 4000 loss: 0.6949951975941658\n",
            "  batch 5000 loss: 0.6953593322634697\n",
            "  batch 6000 loss: 0.6946054560542106\n",
            "  batch 7000 loss: 0.6947021909356117\n",
            "  batch 8000 loss: 0.6948152198195457\n",
            "LOSS train 0.6948152198195457 valid 0.6931531940843677\n",
            "EPOCH 12:\n",
            "  batch 1000 loss: 0.6948861628770828\n",
            "  batch 2000 loss: 0.6945584919452668\n",
            "  batch 3000 loss: 0.6948979738950729\n",
            "  batch 4000 loss: 0.6949735718965531\n",
            "  batch 5000 loss: 0.6953199385404587\n",
            "  batch 6000 loss: 0.694632827937603\n",
            "  batch 7000 loss: 0.6947135420441628\n",
            "  batch 8000 loss: 0.6948260987401008\n",
            "LOSS train 0.6948260987401008 valid 0.6931928984785763\n",
            "EPOCH 13:\n",
            "  batch 1000 loss: 0.6949349816441536\n",
            "  batch 2000 loss: 0.6945819063186646\n",
            "  batch 3000 loss: 0.6948912394046783\n",
            "  batch 4000 loss: 0.6950011803507805\n",
            "  batch 5000 loss: 0.6952988144755363\n",
            "  batch 6000 loss: 0.694616333603859\n",
            "  batch 7000 loss: 0.6947091118693351\n",
            "  batch 8000 loss: 0.6948213906884193\n",
            "LOSS train 0.6948213906884193 valid 0.6931545763131387\n",
            "EPOCH 14:\n",
            "  batch 1000 loss: 0.694879598736763\n",
            "  batch 2000 loss: 0.6945864776968956\n",
            "  batch 3000 loss: 0.6948880502581596\n",
            "  batch 4000 loss: 0.6949925629496574\n",
            "  batch 5000 loss: 0.6953620219826698\n",
            "  batch 6000 loss: 0.6946025223135949\n",
            "  batch 7000 loss: 0.6946944192051887\n",
            "  batch 8000 loss: 0.6948211064338684\n",
            "LOSS train 0.6948211064338684 valid 0.6931696566947115\n",
            "EPOCH 15:\n",
            "  batch 1000 loss: 0.6948937972784043\n",
            "  batch 2000 loss: 0.6945520609617233\n",
            "  batch 3000 loss: 0.694910029232502\n",
            "  batch 4000 loss: 0.6949754205346107\n",
            "  batch 5000 loss: 0.6953665643930436\n",
            "  batch 6000 loss: 0.6945964117646217\n",
            "  batch 7000 loss: 0.6947035034298896\n",
            "  batch 8000 loss: 0.6948300989866256\n",
            "LOSS train 0.6948300989866256 valid 0.6931601832774236\n",
            "EPOCH 16:\n",
            "  batch 1000 loss: 0.6948825005888939\n",
            "  batch 2000 loss: 0.6945625067353248\n",
            "  batch 3000 loss: 0.6949041246175766\n",
            "  batch 4000 loss: 0.6949919508099556\n",
            "  batch 5000 loss: 0.6953455931544303\n",
            "  batch 6000 loss: 0.6945851525068283\n",
            "  batch 7000 loss: 0.6947211772799492\n",
            "  batch 8000 loss: 0.6948260319828987\n",
            "LOSS train 0.6948260319828987 valid 0.6931666732937641\n",
            "EPOCH 17:\n",
            "  batch 1000 loss: 0.6948912680149079\n",
            "  batch 2000 loss: 0.6945736834406853\n",
            "  batch 3000 loss: 0.6948740741610527\n",
            "  batch 4000 loss: 0.6949902737736702\n",
            "  batch 5000 loss: 0.6953782216310501\n",
            "  batch 6000 loss: 0.6946047389507294\n",
            "  batch 7000 loss: 0.6946837273836136\n",
            "  batch 8000 loss: 0.6948571202158927\n",
            "LOSS train 0.6948571202158927 valid 0.6931923200334422\n",
            "EPOCH 18:\n",
            "  batch 1000 loss: 0.6949029513001442\n",
            "  batch 2000 loss: 0.6945809826850892\n",
            "  batch 3000 loss: 0.6948917576670647\n",
            "  batch 4000 loss: 0.695002013683319\n",
            "  batch 5000 loss: 0.6953520413041114\n",
            "  batch 6000 loss: 0.6945933988094329\n",
            "  batch 7000 loss: 0.6946673622727394\n",
            "  batch 8000 loss: 0.6948417640924454\n",
            "LOSS train 0.6948417640924454 valid 0.6931932241085025\n",
            "EPOCH 19:\n",
            "  batch 1000 loss: 0.6949132514595986\n",
            "  batch 2000 loss: 0.6945630546808242\n",
            "  batch 3000 loss: 0.6949188772439957\n",
            "  batch 4000 loss: 0.6950066693425179\n",
            "  batch 5000 loss: 0.6953575865030289\n",
            "  batch 6000 loss: 0.6945893987417221\n",
            "  batch 7000 loss: 0.6946763698458671\n",
            "  batch 8000 loss: 0.6948139075040817\n",
            "LOSS train 0.6948139075040817 valid 0.6932038161803697\n",
            "EPOCH 20:\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 30\n",
        "epoch_number = 0\n",
        "\n",
        "best_vloss = 1_00000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    heh.train(True)\n",
        "    avg_loss = train_one_epoch(epoch_number)\n",
        "    train_loss.append(avg_loss)\n",
        "    # We don't need gradients on to do reporting\n",
        "    heh.train(False)\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    for i, (vdata,vlabels) in enumerate(dataloaders['val']):\n",
        "        vdata0,vdata1,vdata2 = vdata\n",
        "        vdata0,vdata1,vdata2 = vdata0.to(device),vdata1.to(device),vdata2.to(device)\n",
        "        vlabels = vlabels.to(device)\n",
        "        voutputs = heh(vdata0.float(),vdata1.float(),vdata2.float())\n",
        "        vloss = loss_fn(voutputs.squeeze(), vlabels)\n",
        "        running_vloss += vloss\n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    val_loss.append(avg_vloss)\n",
        "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "#     if avg_vloss < best_vloss:\n",
        "#         best_vloss = avg_vloss\n",
        "#         model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "#         torch.save(heh.state_dict(), model_path)\n",
        "\n",
        "    epoch_number += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "summary(heh)"
      ],
      "metadata": {
        "id": "e035yOWA_gil"
      },
      "id": "e035yOWA_gil",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4706bfe",
      "metadata": {
        "id": "f4706bfe"
      },
      "outputs": [],
      "source": [
        "predicts = []\n",
        "real = []\n",
        "for i, (vdata,vlabels) in enumerate(dataloaders['test']):\n",
        "        vlabels = vlabels.to(device)\n",
        "        vdata0,vdata1,vdata2 = vdata\n",
        "        vdata0,vdata1,vdata2 = vdata0.to(device),vdata1.to(device),vdata2.to(device)\n",
        "        voutputs = heh(vdata0.float(),vdata1.float(),vdata2.float())\n",
        "        voutputs = torch.nn.functional.sigmoid(voutputs)\n",
        "        pred = voutputs > 0.5\n",
        "        pred = 1 * pred\n",
        "        running_vloss += vloss\n",
        "        for i in pred:\n",
        "            predicts.append(i.item())\n",
        "        for i in vlabels:\n",
        "            real.append(i.item())\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a87f480",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a87f480",
        "outputId": "f5e8f72f-43fc-47ae-f369-8fe5f71ba847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4975333333333333\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_score(real,predicts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae256d64",
      "metadata": {
        "id": "ae256d64"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c246f90b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "c246f90b",
        "outputId": "cecf8360-b008-486b-9cd6-87c0f07feaf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3697b9add0>]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD4CAYAAAAUymoqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfbA8e8hdFBEQKIgggoiIIsQS2BVbMha0LUguKyiIDYsq6KyWJAVUbGtKxbsriK2FcEG6qqoIBJUkCIIWIAf0kTpJcn5/XHubIZhkqnJkOR8nmeembn3vfe+dya5Z956RVVxzjnnElEl0xlwzjlX/njwcM45lzAPHs455xLmwcM551zCPHg455xLWNVMZ6C0NWzYUJs3b57pbDjnXLkxY8aM1araqKQ0FT54NG/enLy8vExnwznnyg0R+SlWGq+2cs45lzAPHs455xLmwcM551zCPHg455xLmAcP55xzCfPg4ZxzLmEePJxzziXMg0cUqnDHHTBxYqZz4pxzuyYPHlGIwL33wjvvZDonzjm3a/LgUYzGjeGXXzKdC+ec2zXFFTxEpLuIzBeRhSJyUzFpeorIXBGZIyJjwpbfLSKzg8e5UbZ7SEQ2hL2/NtjPLBH5UET2C1tXICLfBI/xiZ1qYrKzPXg451xxYs5tJSJZwCjgRGApMF1Exqvq3LA0LYHBQBdVXSsiewXLTwE6Ah2AGsDHIvKuqq4L1ucA9SMO+TWQo6qbROQy4B4gFHQ2q2qH5E83ftnZMHNmWRzJOefKn3hKHocDC1V1sapuA8YCp0ekuRgYpaprAVR1ZbC8DTBZVfNVdSMwC+gO/wtKI4Ebwnekqh+p6qbg7RdA08RPK3Ve8nDOueLFEzyaAEvC3i8NloVrBbQSkc9F5AsR6R4snwl0F5HaItIQOBbYN1g3EBivqstLOHY/4N2w9zVFJC84xhnFbSQiA4J0eatWrYp9hlE0bgy//w6bNye1uXPOVWjpmpK9KtAS6IqVFCaLyCGqOklEDgOmAKuAqUCBiOwDnBOkj0pE+gA5wDFhi/dT1WUisj/wXxH5VlUXRW6rqqOB0QA5OTmazAllZ9vzihXgtwNxzrkdxVPyWEZRaQEsOCyLSLMUK0VsV9UfgAVYMEFVh6tqB1U9EZBg3aHAgcBCEfkRqC0iC0M7E5ETgCFAD1XdGlquqsuC58XAx8F+SkV48HDOObejeILHdKCliLQQkepALyCyp9M4glJEUD3VClgsIlki0iBY3h5oD0xS1bdVNVtVm6tqc2CTqh4YpDsUeBwLHKG2E0SkvojUCDtGF+B/jfbpFgoe3u7hnHM7i1ltpar5IjIQmAhkAU+r6hwRGQbkqer4YF03EZkLFACDVHWNiNQEPhURgHVAH1XNj3HIkUBd4NVgu59VtQdwMPC4iBRiQe+u8B5f6da4sT178HDOuZ3F1eahqu8A70QsuzXstQLXBo/wNFuwHlex9l837PUJxaSZAhwST37TYa+97NmDh3PO7cxHmBejWjVo2NDbPJxzLhoPHiXwsR7OORedB48S+PxWzjkXnQePEnjJwznnovPgUYLsbGvz0KSGGTrnXMXlwaME2dmwaRNs2BA7rXPOVSYePErgYz2ccy46Dx4l8FHmzjkXnQePEvj8Vs45F50HjxJ4ycM556Lz4FGCBg0gK8uDh3PORfLgUYIqVWyOKw8ezjm3Iw8eMYTGejjnnCviwSMGH2XunHM78+ARg89v5ZxzO/PgEYNPUeKcczvz4BFDdjZs3w5r12Y6J845t+vw4BGDj/VwzrmdefCIwee3cs65nXnwiMFLHs45tzMPHjH4/FbOObezuIKHiHQXkfkislBEbiomTU8RmSsic0RkTNjyu0VkdvA4N8p2D4nIhrD3NUTk5eBY00Skedi6wcHy+SJyUiInmqx69aBGDS95OOdcuKqxEohIFjAKOBFYCkwXkfGqOjcsTUtgMNBFVdeKyF7B8lOAjkAHoAbwsYi8q6rrgvU5QP2IQ/YD1qrqgSLSC7gbOFdE2gC9gLbAPsAHItJKVQtSOP+YRHysh3PORYqn5HE4sFBVF6vqNmAscHpEmouBUaq6FkBVVwbL2wCTVTVfVTcCs4Du8L+gNBK4IWJfpwPPBa9fA44XEQmWj1XVrar6A7AwyFup81Hmzjm3o3iCRxNgSdj7pcGycK2AViLyuYh8ISLdg+Uzge4iUltEGgLHAvsG6wYC41V1eXHHU9V84HegQZz5AEBEBohInojkrVq1Ko5TLJkHD+ec21HMaqsE9tMS6Ao0BSaLyCGqOklEDgOmAKuAqUCBiOwDnBOkTztVHQ2MBsjJyUl5bHh2NkyblnK2nHOuwoin5LGMotICWHBYFpFmKVaK2B5UKS3AggmqOlxVO6jqiYAE6w4FDgQWisiPQG0RWRh5PBGpCtQD1sSZj1KRnQ2rVkFBqbauOOdc+RFP8JgOtBSRFiJSHWu0Hh+RZhxBKSKonmoFLBaRLBFpECxvD7QHJqnq26qararNVbU5sElVDwz2NR64IHh9NvBfVdVgea+gN1YLLDh9mdRZJ6hxYygstADinHMujmorVc0XkYHARCALeFpV54jIMCBPVccH67qJyFygABikqmtEpCbwqbV3sw7oE7RjlOQp4N9BSeRXLFgRHPMVYC6QD1xR2j2tQsIHCoZeO+dcZSZawaeLzcnJ0by8vJT2MWUKdOkC770HJ5XJ6BLnnMscEZmhqjklpfER5nHwKUqcc25HHjzi4JMjOufcjjx4xKFOHahb14OHc86FePCIU+iOgs455zx4xM1HmTvnXBEPHnHyyRGdc66IB484ecnDOeeKePCIU3Y2rF0LW7dmOifOOZd5HjziFBrrsXJlyemcc64y8OARJx/r4ZxzRTx4xMlHmTvnXBEPHnEKBQ8f6+Gccx484rbXXvbsJQ/nnPPgEbcaNaB+fQ8ezjkHHjwS4mM9nHPOePBIgM9v5ZxzxoNHArzk4ZxzxoNHAnx+K+ecMx48EpCdDRs2wMaNmc6Jc67SUYXFi2H79kznBPDgkRAf6+GcK3MbN8Lo0fCHP8ABB8BRR8FPP2U6Vx48EuGjzJ1zcVm7Frp1gwsugJdftveJWrgQrrsOmjaFSy6BKlXglltg7lw49FB466305zsBcQUPEekuIvNFZKGI3FRMmp4iMldE5ojImLDld4vI7OBxbtjyp0RkpojMEpHXRKRusPwBEfkmeCwQkd/CtikIWzc++dNOjs9v5Vw58eOPcOml0LkzXH01vPIKLFtWdse/5hr473/tAt+rFzRsaCWGO++Eb76xKqhoCgvh3XfhlFOgVSt46CHo3h0++wy+/hqGDYOvvoL99oPTToMbbshcNZaqlvgAsoBFwP5AdWAm0CYiTUvga6B+8H6v4PkU4H2gKlAHmA7sHqzbPWz7+4Gbohz7SuDpsPcbYuU38tGpUydNl+XLVUF11Ki07dI5l06LF6v2769atapq9eqqubmqtWvbPy6oNm+u+pe/qD76qOqsWaoFBenPw5tv2rFuuUU1P191yhTVm29W7dixKB/77KPar5/qa6+p/vab6q+/qt5/v+oBB9j67GzV225T/b//i36MzZtVL7vM0nburLpkSVpPAcjTWLEhZgLIBSaGvR8MDI5Icw/QP8q2g4Bbwt4/BfSMSCPAo8CNUbafApwY9j6jwSM/X7VKFdVbb03bLp1z6bBokV2Mq1ZVrVFDdeDAogvqtm2qX36p+sADqmedZRfm0EW8Xj3V7t1Vhw9XXbMm9XysXm37b99edevWndcvX676zDOq55xjxwbLc61a9rpLF9WXXoq+bTQvvaRat65qgwaq77yTev4D6QoeZwNPhr3/K/BwRJpxQQD5HPgC6B4s7xYsqw00BBYD14Vt9wywAvgIqB2xz/2A5UBW2LJ8IC84xhkl5HlAkC6vWbNmaftAVVUbN1YdMCCtu3TOJWvRItWLLlLNyrKgceWVqkuXlrxNYaFt9/zz9s/ctq1dCo84QnXTptTy07u3BYOvv46ddts21cmTVW+80YLdV18ld8z58y1Ygergwarbtye3nzBlGTzeAt4AqgEtgCXAHsG6IcA3QfXVi8A1EdtmAY8AF0YsvxH4V8SyJsHz/sCPwAGx8p/OkoeqfUc9eqR1l865RH3/vWrfvhY0atZUveoq1WXLkt/fG2+oiljJJNmqrNdes0vqsGHJ5yNZmzapXnyxHf/oo1P7LDS+4BFPg/kyYN+w902DZeGWAuNVdbuq/gAswNpBUNXhqtpBVU/EqqgWhG+oqgXAWOCsiH32Al6KSLsseF4MfAwcGkf+08pHmTtXxlRh+XJ4/3148EFrgG7dGsaOhSuvtLEP//wn7LNP8sc44wy49154/XUYPDjx7Vetgssug44d4aaofYpKV61a1p33hRdgxgzo0ME+r1JUNY4004GWItICCxq9gPMi0owDegPPiEhDoBWwWESysBLIGhFpD7QHJomIYKWGhcHrHsB3oZ2JSGugPjA1bFl9YJOqbg2O0QWrKitT2dkwf35ZH9W5SmLNGpg9G+bMsefQ619/LUrTsCFcdRUMGgR7752+Y//tb7BoEdxzj42nGDAg/m2vuAJ++816WFWrlr48Jeovf4FOneDss+314sVQt26pHCpm8FDVfBEZCEzEqpieVtU5IjIMK9qMD9Z1E5G5QAEwKAgYNYFPLT6wDugT7K8K8JyI7I6VRmYCl4UdthcwNig+hRwMPC4ihVgX47tUdW5qp5+4UMlDFey0nKtE8vPhhx9g/Xpo2RJ22y35fa1ZA19+aY9p06wranixvl49aNfOLoTt2kHbtvYcurlOuolYCeaHH+Dyy6077Eknxd7u5Zfh1VetG267dqWTt0S0bm2f6fz5pRY4AGTH63PFk5OTo3l5eWnb3/3327idtWthjz3Stlvndi1r18J339kFaP78otcLF+44rqBJE7tYRT6aNNnx19WWLTa+IRQovvzS9gWWrm1b+8V8yCFFgSJyH2Vl/Xobk7F4sY2vaN+++LS//GJ5PfBA+PxzqBpPZc6uT0RmqGpOSWkqxpmWofBR5h48XIVQWAiffmq/nmfNskCxalXR+mrVrBqndWvo0cOed9sNvv/e0n73Hfz737BuXdE2derAQQfZdj/8ADNnFgWdJk3g8MOhf3844ggLGqmUYNJtt91scN8RR9hgvWnTorenqNpAxI0b4dlnK0zgiFflOts0CJ/fqnXrzObFuZR8+601sL70EixZArVrW4NvKEAcdJA9t2gR+8Koav8UoWASenz1Fey7L1x7rV2MDz/cgseurmlTCyBHHWUjuT/5ZOcqoDFj4M03YeRIOPjgzOQzgzx4JMjnt3Ll2s8/W7B48UULHllZVq9/111w+ulWYkiGiP1zZGdD165pzXLGHHqotWf06AHnnQdvvGGfF8D//R8MHAi5udbQXgn5xIgJ8vmtXLmzdq114zzmGGsEvukmCxIPP2xdYN9+2y6OyQaOiuyUU2x+qQkTrPQEVsoaMAC2brXqqlBAqWS85JGg+vWtCtiDh9ulqVpd/UMP2diFbdusGmrYMAsUBxyQ6RyWH1dcYV14H3jAPrfdd7eA++CDNnlhJeXBI0FVqljpw+/p4XZJW7daw/dDD8H06Xahu/RS+OtfrWHa+5cnZ+RI6331t7/ZgLyjjrIBipWYB48k+ChzV2q2b09ukNkvv8Djj8Ojj9ovm4MOsmqpCy4o1b7+lUZWlrUTde0K8+bBM8/YL8lKzINHErKzy/bWAK4SyM+3rqvPPw/NmkGbNtaDJ/R88MFWZxpp+nQrZbz8sgWek0+20dcnnljpL25pV6eO9bpas8Z6kFVyHjyS0LixTR/jXFrk51sJYcwYe962ze4W99FHNrguJDu7KKA0awbjxsHUqTYu4bLLrG6+EtfBl4nate3hPHgkIzsbVq60sVX+486lpKCgKHCMGLHjpHoFBXav6rlzraok9BwakHfggTadRt++1rbhXBny4JGE7Gz7v16zBho1ynRuXLlVUADnn2+B4847d56NNSsL9t/fHqeeWrRcFVavhgYN/NeLyxj/y0uCDxSsoLZssaqfZ58t/h7T6RJe4rjzzsSmARexXy0eOFwG+V9fEnygYAVUWGjVP488AhdeaAPq5swpnWMVFNixXnwRhg9P7v4RzmWYB48khM9v5SqIW26xHksjRsCTT1rg6NAB/v532LQpfccJBY4XXoA77rD9O1cOefBIgldbVTBPP21VRxdfDDfeCP362aR+ffpYMGnb1kYUp6qgwEo1ocAxZEjq+3QuQzx4JKFuXeut58GjAvjwQ7jkEujWDUaNKhqB3aiRDQT7+GMbUXzqqXDWWbB0aXLHKSiAiy6ynlL/+IcHDlfuefAozpo1xa4SsXaPChk8VO2CWhnq5ObOtYDQujW88kr0kd3HHGM3MRoxAt5918ZZPPCAjc2IV0GBlWaef97mlrr55vSdg3MZ4l11o9mwwe5rcMQR1o8+yn2Ss7Mr4PX1q6/g6qvt7mmNG8PYsWU3vXZBgU0+9+23NoimSRMbCNesmY2sTvecTCtW2IyptWpZlVS9esWnrV7dutGee65Nw33ttfDcczB0KNSsafNJbdliz+GvQ89ff23HGDbM2lacqwA8eERTvbpVZQwbBpMm2aRo/frt0DUyO9tupFYh/PKLVaM88ww0bGjn++STcPzx1hYwaFB6u4WuWGFBIvwxZw5s3hw9fZ06RYEk/LHffnZzoVq1Ejv+pk12j4aVK226iWbN4tuuRQu7QdAbb9gUIH/+c+xtqlSxOs5Eu+M6t4vze5iXZMECCyIffwxHH20TzwW3D7z8cpu8NPxuneXO1q02rfTw4fYr+eqrrUqlXj27j3P//ladc9pp9ks72txK8VixwibpmzrVbnMa/qE1bmz3rQ5/7L233Wzn55+jP1auLNq+YUP7Mq64AvbaK3ZeCgvhnHMsALzxht0AKRkbNlhJrVo1K33UqBH9uZLdmtRVDPHcwxxVrdCPTp06aUoKC1Wfekq1fn3V6tVVb79ddetWHTpUFVS3bUtt9xlRWKj6n/+o7r+/ncRpp6kuWBA93UMPqVarptqiheqMGYkdZ8UK1euuU61VS7VKFdXDDlO96CLVBx5Q/eADW5+MTZssv+PHW95BtUYN1X79VOfMKXnbQYMs/QMPJHds5yoBIE9jXFvjugAD3YH5wELgpmLS9ATmAnOAMWHL7wZmB49zw5Y/BcwEZgGvAXWD5X2BVcA3waN/2DYXAN8HjwviyXvKwSPkl19Ue/Wyj6xNG33j+s8UVJctS8/uy8zMmarHHvu/89BJk2JvM3WqatOmdoEePdqCSklWrFC9/nrV2rUtaJx/fvTglC7ffad66aWqNWvaeXXvbucVmc/HHrP1V1wR+xycq8TiCR4xq61EJAtYAJwILAWmA71VdW5YmpbAK8BxqrpWRPZS1ZUicgpwDfAnoAbwMXC8qq4Tkd1VdV2w/f3ASlW9S0T6AjmqOjAiH3sCeUAOoMAMoJOqri0p/ylVW0Xzzjs2g+nPP/Mol5L78V10OKaExtZ02LrVqmt++mnnx5Il1pi82242OV5Jz9OnwxNPwB57WHvOJZfEX62yejX85S/WBnT++XbfiMjZRVetgnvvtSqqLVvsjnW33FJ2M72uXg2PPWbHX7HCqsCuvRZ697YZak89Fbp3t9lovTrJuWLFU20VT/DIBYaq6knB+8EAqjoiLM09wAJVfTJi20FATVX9R/D+KWCiqr4SlkaAR4AfVfXuEoJHb6Crql4SvH8c+FhVXyop/2kPHgAbNrD84lvZa+w/2b5nY2reOxzatbNW9MaNrcE9EevX7xwUfvyx6HVkn+AqVWCffazBuFkzCx7r1tl+Ip/DG6Gzsqxt4LbbYM89Ez/vggIbozBsmJ3va69ZYFi9uihobNpkF+tbbvlf+1CZ27IFXnoJ7r8fZs+272XDBpuF9tNP/eZIzsUQT/CI5+dXE2BJ2PulwBERaVoFB/wcyMKCzXtYtdRtInIfUBs4FqvaCmXwGeDkYNl1Yfs7S0SOxko8f1PVJcXko0m0DIvIAGAAQLN4e9Ikom5dto64nyPH9ua9OhdT86KLdlxfv75dsEKPxo3tea+94Pffdw4Qv/664/bVqxf1Jjr5ZHsOfzRtGv/d5rZvtwvnunXWKymeRuXiZGVZ99TcXCuF5ORYoBgzBjZutK6st95qYyEyqWZNG8ndty+8/z7cd5+V0N56ywOHc2mSrrJ7VaAl0BVoCkwWkUNUdZKIHAZMwdoxpgIFoY1U9cKgWuxfwLnAM8AE4CVV3SoilwDPAcclkhlVHQ2MBit5pHhuUTVuDHkcxhMD8rip+zewfLmVEFassOfQY/p0e96woWjj2rWheXMLBEccUfR6v/3sdePG6esaW62aBbNke0pFc9JJ1tOoZ0+rBuvZ00oabdum7xjpIGIjx7t1y3ROnKtw4gkey4Dwey42DZaFWwpMU9XtwA8isgALJtNVdTgwHEBExmClif9R1QIRGQvcADyjquFDu58E7gnLR9eIfHwcR/5LRa1a1qN1+aqq9gs8lg0brIvp7rvbfRjSPeitrDVrZoMJV6ywAX3OuUolnp+304GWItJCRKoDvYDxEWnGEVzYRaQhVo21WESyRKRBsLw90B6YJObAYLkAPYDvgvfhw7l7APOC1xOBbiJSX0TqA92CZRmTnZ3AFCV169pNfRo2LP+BI6RqVQ8czlVSMUseqpovIgOxC3UW8LSqzhGRYVh3rvEUXdjnYtVSg1R1jYjUBD61+MA6oE+wvyrAcyKyOyBY28hlwSGvEpEeQD7wK9Z1F1X9VUT+gQUzgGGqGtFYULYq7PxWzjkXg48wT8G558LMmTZ7t3POVRTx9LbyWXVTkFC1lXPOVSAePFKQnW09b4ubz8855yoqDx4pCN3LvMJNze6cczF48EiB38vcOVdZefBIgd/L3DlXWXnwSIEHD+dcZeXBIwWNGtmzBw/nXGXjwSMF1arZgHEPHs65ysaDR4qys73B3DlX+XjwSJEPFHTOVUYePFLk81s55yojDx4pCpU8KvgUYc45twMPHilq2dKmJ3nzzUznxDnnyo4HjxRdeCF06gT9+sHSpZnOjXPOlQ0PHimqXh1eegm2boU+faCgIPY2zjlX3nnwSIOWLWHUKPjkE7jrrkznxjnnSp8HjzQ5/3zo3Rtuuw2mTs10bpxzrnR58EgTEXj0Udh3XzjvPLvPh3POVVQePNKoXj1r/1iyBC65xLvvOucqLg8eaXbkkTBsGLz8Mjz7bKZz45xzpSOu4CEi3UVkvogsFJGbiknTU0TmisgcERkTtvxuEZkdPM4NW/6UiMwUkVki8pqI1A2WXxvsZ5aIfCgi+4VtUyAi3wSP8cmfdum68Ubo2hWuvBIWLMh0bpxzLv1iBg8RyQJGAX8C2gC9RaRNRJqWwGCgi6q2Ba4Jlp8CdAQ6AEcA14vI7sFmf1PVP6hqe+BnYGCw/GsgJ1j+GnBP2KE2q2qH4NEjqTMuA1lZ8MILUKMG9Opl3Xidc64iiafkcTiwUFUXq+o2YCxwekSai4FRqroWQFVXBsvbAJNVNV9VNwKzgO5BmnUAIiJALUCD5R+p6qZg+y+ApsmeXCY1aQJPPw1ffw1//3umc+Occ+kVT/BoAiwJe780WBauFdBKRD4XkS9EpHuwfCbQXURqi0hD4Fhg39BGIvIM8AvQGvhXlGP3A94Ne19TRPKCY5wRR94z6vTT4fLL4f774b33Mp0b55xLn3Q1mFcFWgJdgd7AEyKyh6pOAt4BpgAvAVOB/43BVtULgX2AecC54TsUkT5ADjAybPF+qpoDnAc8KCIHRMuMiAwIgkzeqlWr0nOGSbr3XmjXDi64wO/74ZyrOOIJHssIKy1g1UjLItIsBcar6nZV/QFYgAUTVHV40EZxIiDBuv9R1QKsKuys0DIROQEYAvRQ1a1haZcFz4uBj4FDo2VYVUerao6q5jQK3Ss2Q2rVsu6769ZZACkszGh2nHMuLeIJHtOBliLSQkSqA72AyJ5O47BSB0H1VCtgsYhkiUiDYHl7oD0wScyBwXIBegDfBe8PBR7HAkeo7QQRqS8iNcKO0QWYm9RZl7F27azqauJEGD0607lxzrnUxQweqpqP9YSaiFUvvaKqc0RkmIiEejxNBNaIyFzgI2CQqq4BqgGfBstHA32C/QnwnIh8C3wL7A0MC/Y1EqgLvBrRJfdgIE9EZgbHuEtVy0XwALj0UsjNtWosL30458o70Qo+DDonJ0fz8vIynQ0Axo61+a/eeQf+9KdM58Y556ITkRlB+3KxfIR5GTrzTNh7b/hXtH5lzjlXjnjwKEPVq9ucV+++CwsXZjo3zjmXPA8eZWzAAKhaFR55JNM5cc655HnwKGN77w1nn22jzzduzHRunHMuOR48MuDKK+1+Hy+8kOmcOOdccjx4ZEBuLhx6KDz8sN/zwzlXPnnwyAARGDgQZs+GyZMznRvnnEucB48M6d0b9tzTSh+7ElV4/XVYujTTOXHO7co8eGRIrVrQvz+88YbdtnZXUFgIV19tDfpnngkFBbG3cS4dtmyBlStjp3O7Dg8eGXTZZXbBfvzxTOcE8vOhXz8bwHjccTB9ug9mdGXnH/+AQw7xHyzliQePDGreHE47zSZLzOTdBrdutTsePvssDB0KH3wAp5wCQ4bAjz9mLl+u8pg61Uoes2dnOie7rsJCGDFi16lS9uCRYQMHwqpV8OqrmTn+pk1206rXX4cHHoDbbrMG/UcegSpVbEJH7xHmSpMqzJplr6dMyWxedmVTpthdSXeVmbk9eGTYCSfAQQdlpuH899/hpJPg/ffhqafgmmuK1jVrBnfeadPIv/hi2efNVR7Ll8OaNfb6888zm5dd2YQJ9jx1ambzEeLBI8NC3XanTbN2hrKyapW1bXzxhd2s6qKLdk5z+eVw5JEWVDJ8Q0ZXgYVKHXvv7SWPkoSCx7Rpu0bbkAePXcD550PdumVX+li2DI4+GubOhTffhJ49o6fLyoInn7S7IF57bdnkzVU+oeDRrx/88IOVRNyOFi2CefOgUx6i7q0AABtPSURBVCdYv95eZ5oHj13A7rvbLWrHji39X/iLFsEf/2gB5L334OSTS07fti0MHmxTqbz3XunmzVVOs2bBvvtaJw3w0kc0oVLH8OH2vCtUXXnw2EVccQVs22a/9EvL7Nlw1FFWkvjvf+GYY+Lb7u9/h9atrfF8w4bSy5+rnGbNgvbtoWNHqFHDg0c0EyZAmzbQrRs0aLBrBI+qmc6AMwcfbI3njz4KgwbZtO2JUrUi7erVVoKJfH7ySfvnnDzZShTxqlEDnnjCAs+tt9r92J1Lh23brArm1FPtfjeHHebBI9Lvv9v/7HXXWRvpkUd68HARBg6EM86A8eNthHdJNm60dK++CosXFwWIbduip69WDdq1s/QHHJB43v74RxvU+M9/2piQww9PfB/ORZo3zwaotm9v7zt3ti7jmzfbLAzOqovz821MGNjEqm+/DWvXQv36mcuXB49dyKmnWhfZhx+OHjy2b4dJk2DMGBg3zsZoNGlixf2OHaFRI2jYMPrzbrvZr5ZUjBhhAat/f5gxwwJSOq1bZ6Ptv/vOAumhh6Z3/27XE2osDwWPLl3gnnvs7+uPf8xcvnYlEybY//GRR9r73Fx7njYNunfPXL5Q1Qr96NSpk5Ynd92lCqqzZ9v7ggLVyZNVL71UtUEDW7fnnqqXXKL6ySe2viyNG2d5uPPO9O1z5UrVIUNU99jD9l2rlj2ffbbqnDnpO46LrrBQ9dVXVZs3t88+nseRR9p2qbr+etXq1VW3b7f3K1fad3/33anvuyLYvl21fn3V888vWrZunWqVKqq33lp6xwXyNMa1VTSO4cMi0h34J5AFPKmqd0VJ0xMYCigwU1XPC5bfDQT9KPiHqr4cLH8KyAEEWAD0VdUNIlIDeB7oBKwBzlXVH4NtBgP9gALgKlWdGCvvOTk5mpeXF/McdxVr1kDTptbz5IADbAzGkiVQu7aNBD/vPGs0q149c3k85xz7NTRrFrRqlfx+fv4Z7rvP2lO2bIE//xluuglatrSqiwcesAb6886zke8tW6bvHJxZutQ6a4wfbyW9E06Ivc3cuVZtsmgR7L9/asc/6SSrbv3qq6JlrVpZG+Cbb6a274pg8mTr2PLqqzZhacgf/gDZ2TaItzSIyAxVzSkxUazoggWMRcD+QHVgJtAmIk1L4GugfvB+r+D5FOB9rHqsDjAd2D1Yt3vY9vcDNwWvLwceC173Al4OXrcJjl0DaBHkKStW/stbyUNV9cIL7ddX1aqqp5yi+uKLquvXZzpXRZYvt1LCMcckV/KZN0+1b187v6pVVS+4QHXu3J3TrV6teuON9ks3K0v1ootUf/ghvmP8/rvq22+rDhqkethhqh077lqfYaYVFKiOGqW62272+Y4cWfTrP5avv7a/zxdeSD0f2dn2txCub1/Vhg3TU7Ip766/XrVaNft7DnfJJar16pVezQNxlDziCR65wMSw94OBwRFp7gH6R9l2EHBL2PungJ4RaQR4FLgxeD8RyA1eVwVWB2l2OG54upIe5TF4rFxp/5irVmU6J8V78kn763nkEdVNm+L7I54+XfXMM1VF7IJ15ZWqP/4Ye7vly1Wvvlq1Rg37R7r8ctWlS3dM89tvqm+9Zf9sOTlWrAerEsnNtdeDByd3rhXNnDmqXbrYZ3LCCaoLFya2/fbtqnXqqF5xRWr5WLHC8nD//TsuHz3ali9YkNr+K4KDDlI98cSdlz/77I7V2+mWruBxNlZVFXr/V+DhiDTjggDyOfAF0D1Y3i1YVhtoCCwGrgvb7hlgBfARUDtYNhtoGpZmUbDtw0CfsOVPAWfHyn95DB7lQWGhateu9hcUelSrplq3rv1qbNJEdf/9Vdu0UT30UNX27S1NvXrWvrFiReLHXLLE2n6qVrVActVVqtddp9qp047B4uijrT74v/+1wKaq+te/Wv525QvShAmWz/z80tn/li2qQ4faZ7TnnnYBSvbX/bHHWmkuFR98YN/ZBx/suHz2bFv+zDOp7b+8mz/fPoeHHtp53Xff2bonnyydY8cTPNLV26oqVnXVFWgKTBaRQ1R1kogcBkwBVgFTsfYKAFT1QhHJAv4FnBsEk5SJyABgAECzZs3SsUsXQQRee816fm3caG0WW7faI/Q6/Hn7dmu7uOwyG1GfjKZNbRzMDTfY/R8eftjGw+Tmwi23QNeucMQR0bt43n239VC75hqrr9/VqNo5fPONtTucf3569z9lClx8sbVX9O4NDz4Ie+2V/P5yc+0z3bgR6tRJbh+RPa1CDj4Y9tjD8ty3b/J5zKQtW6z9rn9/6yKfjNCo8lAX3XCtWtmdSKdOtWldMiJWdCG+aqvHgAvD3n8IHBZlX2OAk6MsPxp4S73ayiVg1aqikkU87r3Xfq1NmFB6eUrW9OmWtxo1VPfbz0oJ6bB+vVUviajuu6+1A6XDhAmW348/Tn4ffftam0c0f/qTatu2ye8700aMsM+nS5fkS3fHHKN6yCHFrz/5ZCvZlwbiKHnEMz3JdKCliLQQkepYI/b4iDTjsFIHItIQaAUsFpEsEWkQLG8PtAcmiTkwWC5AD+C7YF/jgQuC12cD/w1OZjzQS0RqiEgLrKTzZRz5dxVUw4aJDSS78kqbZuWaa+yX4a7kiSesR92//w0//ZS+u0tedJHdm+XKK2HOnNhzmcUrNOYglZHOoWlJounc2fL722/J7z9Tli+3OagaN7Yp5t99N/F9rF0Ln30WvdQRcuSRVpLM2GcUK7rYdZuTse60i4AhwbJhQI/gtWA9puYC3wK9guU1g2VzsbaQDsHyKlhbyLdYG8eLFPXCqgm8CizEgsP+YfkYEuRhPvCnePLuJQ8XbtIk+0U4fHimc1Jk/XprK7rwQvuVeuyxqo0aWX/+VLz7rp3rHXekJ5+RWrZU7dEjuW23b7dS1vXXR1//4YeW93feST5/mXLhhda+NmeOtfv94Q+J94p68UU7/6lTi0/z/vuWZuLE1PIbDeloMC/vDw8eLtKf/6xau7bqzz9nOifmiSfsP3HKFHv/xRf2ftiw5Pe5ebPqAQdYb510VYFFOv98C3LJVMvMnWvn+Pzz0devX2/ds2++ObU8lrW8PKsiDAXFF16w8xw7NrH99OqlutdeJQed33+3Yw0dmnx+ixNP8PBZdV2lc//9dj/o66/PdE7M6NHWqBqqCjriCBswOXKkzVmWjLvvtkF8o0bZxJalITfXBvgtXpz4tsU1lofUrWsD4crTJImqViXasCHcfLMt69XLvttbbrH5qeKxfbtVdZ1yit0Kuji7724TnGZqkkQPHq7Sad7cesK88gp89FHy+9E03Nv9m2/sDpIXX7zj3GN33GE9mUaMSHyfCxfadr17w/HHp57H4oTmWErm4jVrlvWUa926+DSdO9v8TfFedDPt1VetnWL4cKhXz5ZlZdl3+f338Oyz8e3ns89sJt2S2jtCcnPtMyosTDrbSfPg4SqlG26wIHLVVYlfnH7/3S7MBx9skzmm4oknoGZN6NNnx+Vt2tgNwkaNsmlc4qVqk0pWr25Tv5Smdu2shJBs8GjduuRSUefOFkBDpZTS9OOPqd3adfNmu5XCH/6w8y2de/Sw0uTtt8fXUWPCBPv+TjwxdtrcXGswnz8/uXynwoOHq5Rq1bLqq9mzrTdSvGbMsBmMX33V/mHv2mmWt/ht2mR3aDz7bOuzH2noUAsGt98e/z5ff93mO7rjDrsneGnKyrKp+ZMNHsVVWYV06WLPpV119dhjNkfXWWdZlVEy7rvPgvyDD9rnEk4E7rzT5hF79NGS96NqweO44ywwx5JK6S9lsRpFyvvDG8xdcQoLbeqHevVij3gvLFT9179sdHbTpqqffabap4/1GIpnipVonnnGGlM/+aT4NH/7m42ejzb3V6R162xkf4cO8c9TlaohQ6xhe8OG+LdZu9bO+667Sk5XWGjn06tXanksyciRlpfQDAhnn534Z7d0qXXAOPPMktOdcILNvlBSL7p58ywfo0bFd+yCAptn7uKL489vPPDeVh48XMnmzbPpTvr1Kz7N2rV2YQCbqDI059jPP6vWrKl63nnJHbtzZ+sNVVJvpZUrbfLCWBcmVZuqJVb3znR76y075kcfxb/N5Mkadzfcc85RbdYs6ewVq7DQprAB1Z49VbdutTm2wL7PRKaIOf98+1GxaFHJ6aZN05i96O65x9L89FP8x+/eXbVdu/jTx8ODhwcPF4fQRXfatJ3XffmlaosW9ut65Midu04OGWLbfvFFYscMzd90772x095+e/H5C5k1y/KY7l+gsaxerQnf3+Xhh22byMkto3nwQUu7ZEnyeYxUWGglOrCZmsMDRWhk+IUXxjc2IxQQbropvmOfcYbq7rvb5xbNUUfZuJBE3H67ddn97bfEtiuJBw8PHi4Ov/9u02QcdljRBaOw0C5c1arZtB6hMRiR1q1TbdzYShGJjHe4+mr7tRrPzMnr1tl4iuOOi76+oMCmwWjQoPiLUmlq1Ur1tNPiTz9ggE3MGM/n9eWXdpV6+eXk8xcuP98CLNjEmtECxG232fpLLy05j4WFNmNz48bxD+icPdsu9IMG7bxu9Wqrokx0bMvEiZbf999PbLuSePDw4OHi9Pzz9t/w1FOqv/5qvxDBLopr1pS8bWiQ3yuvxHeszZvt7nDnnht//kK/wKNdIEJtJ089Ff/+0umCCxK7/8aRR9qMzPHYts2m77/66qSzt8O+zjvPPqu//734/BYWWkkC7LjFpQuNAk/0c//rX626c9myHZf/+98as4QZzW+/WUBKZVBpJA8eHjxcnAoLrfTQqJFNTFi1qup998V3QczPtwnsWrSIbzR3aNTxhx/Gn78tW6zuv1OnHfO0erVduLt0KftbEoc89pidz/ffx05bUGD3Arnqqvj3f/TRVipMxebNqqefbvkcMSJ2+sJC1WuusfQ33LDz38GGDdZxomPHxD/3xYutRHvppTsu79nTSsDJfI9t29pkkuniwcODh0vAjBlWbbDffom3YYTmzBo5Mnbao4+2qUMSvUiEbgD06qtFywYMsLaOmTMT21c6zZypJU41Em7hQk34PhSDB1sw37gxufxt2GC96sDaW+JVWKh62WW2XeT9wkNVW5MnJ5enyy+3cwrdiGvrVmsLKanjRkn697fSbLp+QHjw8ODhEjRrVvINjyefbN1+S2rHCN3EJ1Y31Wjy820K7latrDvp1KlWXXHttcnlN13y861H2GWXxU77n//Y+X/5Zfz7T2X6999+s1JZlSrJ3VyqoMAu6OGTaf78s1Wl9eyZ+P5C/u//bB99+tj70I2xxo1Lbn+hO3t+913yeQrnwcODhytDc+ZYKWDgwOLTXHed/eL85ZfkjjFunP3XPvqo3aFxn31Sn303HY4/3saXxDJ0qAW8REoRyfToUrUg3rGjVRGFl9YSlZ9vF/lQ77jzzrPxPT/8kPw+VVVvvNE+i1mzim6znMh4mXBz5mha777owcODhytjl19uAWTevJ3Xbdli7RPxjNkoTmGhNThXraoJNdKXtptvtl/369eXnO7MM63klKjWrVVPPTX+9Bs3WjtJzZrpuQHW9u025iR0y+UhQ1Lf55o1VlLt0cOmbj/55OT3VVBg+xowIPV8qcYXPHx6EufSaOhQuy3roEE7rxs3zmbJHTAg+f2L2JQo+fnQrZtNbbIryM21yfmmTy85XTzTkkTTubNNUxLPBIAFBfCXv0BeHrz8cnpugFW1Krz4IpxzDhx4oE2smao997S/k/HjbWbieCZCLE6VKjZ/1hdfpJ6vuI9ZdodyruJr1AiGDIG33oIPP9xx3RNPwH77xTfhXUmOOcam7B4zZseZeDMpnjsLbthg08QnGzx+/RUWLIiddtAgC9QPPmiTEqZLtWo2E/N338U371Q8rr666F7yp56a2r5yc22utvXrU89XPDx4OJdmV11lM/Zed13RTK2LFlkw6d+/5Hs0xKt7d2jQIPX9pMuee8JBB5UcPObMsUqfZIJHvJMkPvwwPPCAXZSvuirx48QjcuLDVNStaxNzXncdNG2a2r5Cpb8vy+jm3B48nEuzmjXtZkwzZ8Jzz9myJ5+0oHHhhZnNW2nKzbVqEy3mPiexbgBVklatLEB9/nnxaSZMsKBx+umlPx19Op11Ftx7b+r7Ofxwey6rqisPHs6VgnPOsYvpkCGwdi0884xVSzRpkumclZ7Ona1NZ+HC6OtnzYLddrOqu0RVqWKfZ3Eljxkz7K59HTta20Q6SwflRf36do+Zspqe3YOHc6VAxO4X8ssv1mC7YoXdLbAii3VviVmz4JBDkq+269zZ2hvWrNlx+c8/W2Bu1MhKH3XqJLf/iiBW6S+dPHg4V0qOPNJ+DX/xhdVnd++e6RyVrjZt7L7a0YKHavI9rUJC7R7h+//9dwvOmzfD229Ddnby+68IcnMtuH7/fekfK67gISLdRWS+iCwUkaid1ESkp4jMFZE5IjImbPndIjI7eJwbtvzFYJ+zReRpEakWLB8kIt8Ej9kiUiAiewbrfhSRb4N1eamdunOlb8QI+yV86aXW3bMiC3UXjRY8li6126WmEjwOO8yqo0JVV9u3W1fl+fPtDopt2ya/74oi1OutLNo9YgYPEckCRgF/AtoAvUWkTUSalsBgoIuqtgWuCZafAnQEOgBHANeLyO7BZi8CrYFDgFpAfwBVHamqHVS1Q7DPT1T117DDHRusz0nynJ0rM82bw08/pWdcQHmQmwvffrtzd9FUGstDateGQw+14KFqAfmDD6wL9PHHJ7/fiqSk0l+6xVPyOBxYqKqLVXUbMBY4PSLNxcAoVV0LoKorg+VtgMmqmq+qG4FZQPcgzTthoxm/BKJ1VOsNvJToSTm3K2nQoPI04BY3WDAUPNq1S23/XbpYV9Rhw+Dpp+GWW6Bv39T2WZGUVPpL+7HiSNMEWBL2fmmwLFwroJWIfC4iX4hIqHZ3JtBdRGqLSEPgWGDf8A2D6qq/Au9FLK+NBZrXwxYrMElEZohICuN0nXOl4Ygj7Dny4jVrlpXC6tVLbf+dO1v7xtCh0KcP3H57avuriI480kp/GzaU7nHSVQtbFWgJdMVKEJNF5BBVnSQihwFTgFXAVKAgYttHsNLJpxHLTwM+j6iy+qOqLhORvYD3ReQ7VZ0cmZkgsAwAaNasWepn55yLS3HdRVNtLA/p0sV6sh11lI2d2VVG2O9Kwkt/xx5beseJp+SxjB1LC02DZeGWAuNVdbuq/gAswIIJqjo8aKM4EZBgHQAichvQCLg2ynF7EVFlparLgueVwBtYldpOVHW0quaoak6jRo3iOEXnXLpEdhfdssUatdMRPJo0gU8+selfatRIfX8VUXGlv3SLJ3hMB1qKSAsRqY5d1MdHpBmHlToIqqdaAYtFJEtEGgTL2wPtgUnB+/7ASUBvVd1hujMRqQccA7wZtqyOiOwWeg10A2YndLbOuVIX2V103jybpiUdwQOs1LHbbunZV0UUmiqmtHtcxay2UtV8ERkITASygKdVdY6IDMOm7R0frOsmInOxaqlBqrpGRGoCn4qVLdcBfVQ1P9j1Y8BPwNRg/X9UdViw7s/ApKCRPaQx8EaQtiowRlV3aCdxzmVe+GDBVq3S09PKJSY310pnqqVXtSdaFkMRMygnJ0fz8nxIiHNlpbDQfv326gWPPWaT/j3yiDXgVpZeZ5n27bewaZPNd5VM8BCRGbGGQ1TwYUvOubIW2V101izrouuBo+wcckjpH8OnJ3HOpV34vSXS1dPK7Vo8eDjn0i7UXXTCBFi50oNHReTBwzmXdqHuoo8/bs8ePCoeDx7OubTbYw+bZ2lyMIS3LOrgXdny4OGcKxWhLrv77AMNG2Y2Ly79PHg450pFKHh4lVXF5MHDOVcqPHhUbD7OwzlXKg4+GG69Fc47L9M5caXBg4dzrlSI+JTpFZlXWznnnEuYBw/nnHMJ8+DhnHMuYR48nHPOJcyDh3POuYR58HDOOZcwDx7OOecS5sHDOedcwir8bWhFZBV2r/RkNARWpzE7mVbRzgcq3jlVtPOBindOFe18YOdz2k9VG5W0QYUPHqkQkbxY9/EtTyra+UDFO6eKdj5Q8c6pop0PJHdOXm3lnHMuYR48nHPOJcyDR8lGZzoDaVbRzgcq3jlVtPOBindOFe18IIlz8jYP55xzCfOSh3POuYR58HDOOZcwDx5RiEh3EZkvIgtF5KZM5ycdRORHEflWRL4RkbxM5ycZIvK0iKwUkdlhy/YUkfdF5PvguX4m85iIYs5nqIgsC76nb0Tk5EzmMREisq+IfCQic0VkjohcHSwvz99RcedULr8nEakpIl+KyMzgfG4PlrcQkWnBNe9lEakec1/e5rEjEckCFgAnAkuB6UBvVZ2b0YylSER+BHJUtdwObhKRo4ENwPOq2i5Ydg/wq6reFQT6+qp6YybzGa9izmcosEFV781k3pIhInsDe6vqVyKyGzADOAPoS/n9joo7p56Uw+9JRASoo6obRKQa8BlwNXAt8B9VHSsijwEzVfXRkvblJY+dHQ4sVNXFqroNGAucnuE8OUBVJwO/Riw+HXgueP0c9o9dLhRzPuWWqi5X1a+C1+uBeUATyvd3VNw5lUtqNgRvqwUPBY4DXguWx/UdefDYWRNgSdj7pZTjP5YwCkwSkRkiMiDTmUmjxqq6PHj9C9A4k5lJk4EiMiuo1io3VTzhRKQ5cCgwjQryHUWcE5TT70lEskTkG2Al8D6wCPhNVfODJHFd8zx4VB5/VNWOwJ+AK4IqkwpFrQ62vNfDPgocAHQAlgP3ZTY7iRORusDrwDWqui58XXn9jqKcU7n9nlS1QFU7AE2xmpbWyezHg8fOlgH7hr1vGiwr11R1WfC8EngD+6OpCFYE9dKh+umVGc5PSlR1RfDPXQg8QTn7noJ69NeBF1X1P8Hicv0dRTun8v49Aajqb8BHQC6wh4hUDVbFdc3z4LGz6UDLoPdBdaAXMD7DeUqJiNQJGvsQkTpAN2B2yVuVG+OBC4LXFwBvZjAvKQtdZAN/phx9T0Fj7FPAPFW9P2xVuf2Oijun8vo9iUgjEdkjeF0L6xg0DwsiZwfJ4vqOvLdVFEG3uweBLOBpVR2e4SylRET2x0obAFWBMeXxnETkJaArNn30CuA2YBzwCtAMm3q/p6qWi0boYs6nK1YVosCPwCVh7QW7NBH5I/Ap8C1QGCz+O9ZGUF6/o+LOqTfl8HsSkfZYg3gWVnh4RVWHBdeIscCewNdAH1XdWuK+PHg455xLlFdbOeecS5gHD+eccwnz4OGccy5hHjycc84lzIOHc865hHnwcM45lzAPHs455xL2/58vzBNshHTyAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(train_loss, c = 'blue')\n",
        "plt.plot([i.item() for i in val_loss], c = 'red')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "113d8395",
      "metadata": {
        "id": "113d8395"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53a2d26a",
      "metadata": {
        "id": "53a2d26a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}